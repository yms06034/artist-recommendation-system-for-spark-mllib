{
  "metadata": {
    "name": "by ALS",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ALS 알고리즘을 사용한 Artist recommendation\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(spark.version)\nprintln(sc.master)\nprintln(sc.sparkUser)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\nmkdir -p /yms060-spark/sungjin/spark/data/audio\n\nwget -O /yms060-spark/sungjin/spark/data/audio/profiledata_06-May-2005.tar.gz https://storage.googleapis.com/aas-data-sets/profiledata_06-May-2005.tar.gz\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\ncd /yms060-spark/sungjin/spark/data/audio\ntar xvfz ./profiledata_06-May-2005.tar.gz\nls -alh\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\nls -alh /yms060-spark/sungjin/spark/data/audio/profiledata_06-May-2005\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\n# export HADOOP_USER_NAME\u003dspark\nyms060-spark/sungjin/spark/hadoop3/bin/hdfs dfs -mkdir -p yms060-spark/sungjin/spark/data/audio\nyms060-spark/sungjin/spark/hadoop3/bin/hdfs dfs -put -f yms060-spark/sungjin/spark/data/audio/profiledata_06-May-2005 yms060-spark/sungjin/spark/data/audio\n\nyms060-spark/sungjin/spark/hadoop3/bin/hdfs dfs -ls -h yms060-spark/sungjin/spark/data/audio\nyms060-spark/sungjin/spark/hadoop3/bin/hdfs dfs -ls -h yms060-spark/sungjin/spark/data/audio/profiledata_06-May-2005\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userArtistDS \u003d spark\n    .read\n    .textFile(\"/yms060-spark/sungjin/spark/data/audio/profiledata_06-May-2005/user_artist_data.txt\")  //--spark.read.textFile(path)....\n\nprintln(userArtistDS.count())\nuserArtistDS.printSchema()\nuserArtistDS.show()\nz.show(userArtistDS.limit(20))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userArtistCSVDF \u003d spark\n    .read\n    .option(\"sep\", \" \")\n    .csv(\"hdfs://yms060-spark:9000/sungjin/data/audio/profiledata_06-May-2005/user_artist_data.txt\") \n    .toDF(\"userid\", \"artistid\", \"playcount\")\n\nprintln(userArtistCSVDF.count())\nprintln(userArtistDS.count() - userArtistCSVDF.count())\nuserArtistCSVDF.printSchema()\nuserArtistCSVDF.show()\nz.show(userArtistCSVDF.limit(20))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistCSVDF.printSchema\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistCSVDF.describe().show()  //--DataFrame.describe()....\n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistCSVDF.summary().show()  //--DataFrame.summary()....\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userArtistCSVDF2 \u003d userArtistCSVDF\n    .selectExpr(\"cast(userid as int)\", \"cast(artistid as int)\", \"cast(playcount as int)\")  //--cast(col as type)....\n\nuserArtistCSVDF2.printSchema\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistCSVDF2.summary().show()  //--DataFrame.summary()....\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistCSVDF2\n    .where(\"playcount \u003d 439771\")\n    .show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// 음악 한곡당 4분이라 가정\n4 * 439771 / 60F/ 24L/ 365F\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "6 * 30 * 24 * 60 / 4\n"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistCSVDF2\n    .where($\"playcount\" \u003e 64800)\n    .withColumn(\"playyear\", round(\u0027playcount * 4 / 60F / 24L / 365F, 3))\n    .orderBy(\u0027playcount.desc)\n    .show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userArtistCSVDF3 \u003d userArtistCSVDF2\n    .filter(\"playcount \u003c\u003d 64800\")\n\nuserArtistCSVDF3.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY)\nprintln(userArtistCSVDF3.count())\nuserArtistCSVDF3.printSchema()\nuserArtistCSVDF3.show()\nz.show(userArtistCSVDF3.limit(20))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(userArtistDS.count() - userArtistCSVDF3.count())\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val artistDS \u003d spark\n    .read\n    .textFile(\"hdfs://yms060-spark:9000/sungjin/data/audio/profiledata_06-May-2005/artist_data.txt\")\n\nprintln(artistDS.count())\nartistDS.printSchema()\nartistDS.show(truncate\u003dfalse)\nz.show(artistDS.limit(20))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val artistDF \u003d spark\n    .read\n    .option(\"sep\", \"\\t\")\n    .option(\"inferSchema\", true)  //--inferSchema \u003d\u003e true....\n    .csv(\"hdfs://yms060-spark:9000/sungjin/data/audio/profiledata_06-May-2005/artist_data.txt\")\n    .toDF(\"artistid\", \"artistname\")\n    \nprintln(artistDF.count())\nprintln(artistDS.count() - artistDF.count())\nartistDF.printSchema()\nartistDF.show(false)\nz.show(artistDF.limit(20))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "artistDF.summary().show()  //--DataFrame.summary()....\n"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "artistDF.filter(row \u003d\u003e {\n    val artistid \u003d row.getString(0)\n    val artistname \u003d row.getString(1)\n    try {\n        artistid.toInt\n        false\n    } catch {\n        case e:Exception \u003d\u003e true\n    }\n    \n}).show(false)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val artistFinal \u003d artistDF.filter(row \u003d\u003e {\n    val artistid \u003d row.getString(0)\n    val artistname \u003d row.getString(1)\n    try {\n        artistid.toInt\n        true\n    } catch {\n        case e:Exception \u003d\u003e false\n    }\n})\n.where(\"artistid is not null\")\n.where(\"artistname is not null\")\n.withColumn(\"artistid\", expr(\"cast(artistid as int)\"))\n\nprintln(artistFinal.count())\nartistFinal.printSchema()\nartistFinal.show(false)\nz.show(artistFinal.limit(20))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "artistFinal.summary().show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "artistFinal.where(\"artistname is null\").show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "artistFinal.where(\"artistname in (\u002733\u0027, \u0027304\u0027, \u00271988\u0027)\").show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "artistDS.where(\"value like \u00271335772%\u0027 or value like \u00271344623%\u0027 or value like \u00272032179%\u0027\").show(false)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "artistFinal.where(\"artistname in (\u0027\u0001\u0027, \u0027￿￿￿￿￿￿￿￿￿￿￿￿くȁ\u0027)\").show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "artistDS.where(\"value like \u00271165062%\u0027 or value like \u002710495051%\u0027\").show(false)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(artistDS.count() - artistFinal.count())\n"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val artistAliasDS \u003d spark\n    .read\n    .textFile(\"hdfs://yms060-spark:9000/sungjin/data/audio/profiledata_06-May-2005/artist_alias.txt\")\n    \nprintln(artistAliasDS.count())\nartistAliasDS.printSchema()\nartistAliasDS.show()\nz.show(artistAliasDS.limit(20))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val artistAliasDF \u003d spark\n    .read\n    .option(\"sep\", \"\\t\")\n    .option(\"inferSchema\", true) \n    .csv(\"hdfs://yms060-spark:9000/sungjin/data/audio/profiledata_06-May-2005/artist_alias.txt\")\n    .toDF(\"badid\", \"goodid\")\n    \nprintln(artistAliasDF.count())\nartistAliasDF.printSchema()\nartistAliasDF.show()\nz.show(artistAliasDF.limit(20))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "artistAliasDF.summary().show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "artistAliasDF.where(\"badid is null\").show(false)\nartistAliasDF.filter(\"goodid is null\").show(false)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val artistAliasFinal \u003d artistAliasDF\n    .filter(\"badid is not null\")\n    .filter(\"goodid is not null\")\n\nprintln(artistAliasFinal.count())\nartistAliasFinal.printSchema()\nartistAliasFinal.show()\nz.show(artistAliasFinal.limit(20))\n\nartistAliasFinal.createOrReplaceTempView(\"artistAliasFinal\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "artistAliasFinal.summary().show(false)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(artistAliasDS.count() - artistAliasFinal.count())\n"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistCSVDF3.printSchema()\nartistAliasFinal.printSchema()\n\nuserArtistCSVDF3.createOrReplaceTempView(\"userArtistCSVDF3\")\nartistAliasFinal.createOrReplaceTempView(\"artistAliasFinal\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nselect\n    distinct(badid)\nfrom \n    artistAliasFinal\nlimit 20;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//artistAliasFinal.select(distinct($\"badid\")).show()  \nartistAliasFinal.select(countDistinct($\"badid\")).show()  \n\nspark.sql(\"select distinct(badid) from artistAliasFinal\").show()  \nspark.sql(\"select count(distinct(badid)) from artistAliasFinal\").show() \n"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(artistAliasFinal.count())\nartistAliasFinal.select(expr(\"count(distinct(badid))\")).show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nselect \n    *\nfrom\n    userArtistCSVDF3 ua\n    left outer join\n    artistAliasFinal aa\n    on \n    ua.artistid \u003d aa.badid\nwhere\n    true\nlimit 20;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nselect \n    ua.*,\n    aa.*,\n    case\n        when aa.badid is not null then aa.goodid\n        else ua.artistid\n    end\n    as artistid2\nfrom\n    userArtistCSVDF3 ua\n    left outer join\n    artistAliasFinal aa\n    on \n    ua.artistid \u003d aa.badid\nwhere\n    true\n--and aa.badid is not null\nlimit 20;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nselect \n    ua.userid,\n    case\n        when aa.badid is not null then aa.goodid\n        else ua.artistid\n    end\n    as artistid,\n    ua.playcount\nfrom\n    userArtistCSVDF3 ua\n    left outer join\n    artistAliasFinal aa\n    on \n    ua.artistid \u003d aa.badid\nwhere\n    true\nlimit 20;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userArtistCSVDF4 \u003d spark.sql(\"\"\"\n\nselect \n    ua.userid,\n    case\n        when aa.badid is not null then aa.goodid\n        else ua.artistid\n    end\n    as artistid,\n    ua.playcount\nfrom\n    userArtistCSVDF3 ua\n    left outer join\n    artistAliasFinal aa\n    on \n    ua.artistid \u003d aa.badid\nwhere\n    true\n--and aa.badid is not null\n\n\"\"\")\n\nprintln(userArtistCSVDF4.count())\nuserArtistCSVDF4.printSchema()\nuserArtistCSVDF4.show()\nz.show(userArtistCSVDF4.limit(20))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(userArtistCSVDF3.count() - userArtistFinal.count())\n"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(userArtistCSVDF3.select(\"artistid\").distinct().count() - userArtistFinal.select(\"artistid\").distinct().count())\n"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "createOrReplaceTempViewcreateOrReplaceTempView%sql\n\nselect \n    userid,\n    artistid,\n    count(playcount) as cnt\nfrom\n    userArtistFinal\ngroup by userid, artistid\nhaving\n    true\nand cnt \u003e 1\norder by cnt desc\nlimit 20;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nselect \n    *\nfrom\n    userArtistFinal\nwhere\n    true\nand userid \u003d 2133748\nand artistid \u003d 1018110\n;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nselect\n    *\nfrom \n    artistAliasFinal\nwhere\n    true\nand goodid \u003d 1018110\n;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nselect \n    userid,\n    artistid,\n    sum(playcount) as playcount\nfrom\n    userArtistFinal\ngroup by userid, artistid\norder by playcount desc\nlimit 20;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userArtistFinal2 \u003d userArtistFinal\n    .groupBy(\"userid\", \"artistid\")\n    .agg(sum(\"playcount\").as(\"playcount\"))\n    .filter(\"playcount \u003c\u003d 64800\") \n\nuserArtistFinal2.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY)    \nprintln(userArtistFinal2.count())\nuserArtistFinal2.printSchema()\nuserArtistFinal2.show()\nz.show(userArtistFinal2.limit(20))\n\nuserArtistFinal2.createOrReplaceTempView(\"userArtistFinal2\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(userArtistFinal.count() - userArtistFinal2.count())\n"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistFinal2.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY) // userid_artistid_playcount\nprintln(userArtistFinal2.count())\n\nartistFinal.cache()  // artistid_name\nprintln(artistFinal.count())\nartistAliasFinal.persist()  // badid_goodid\nprintln(artistAliasFinal.count())\n"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistFinal2.unpersist()\n\nartistFinal.unpersist()\nartistAliasFinal.unpersist()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nselect \n    *\nfrom\n    mycatalog.mykeyspace.user_artist_data\nlimit 20;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistFinal2.printSchema\n\nuserArtistFinal2\n    .limit(100000) \n    .writeTo(\"mycatalog.mykeyspace.user_artist_data\")\n    .append\n    "
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userArtistFinal3 \u003d spark.table(\"mycatalog.mykeyspace.user_artist_data\")\n\nuserArtistFinal3.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY) \nprintln(userArtistFinal3.count())\n\nuserArtistFinal3.printSchema\nuserArtistFinal3.show\n"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.recommendation.ALS\n\nval als \u003d new ALS()\n    .setUserCol(\"userid\")\n    .setItemCol(\"artistid\")\n    .setRatingCol(\"playcount\")\n    .setImplicitPrefs(true)\n    .setMaxIter(5)\n    .setRegParam(0.1)  \n    .setAlpha(40)  \n    .setRank(10) \n    .setColdStartStrategy(\"drop\") \n    .setSeed(11L)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(\"\\n\u003e\u003e\u003e\u003e als.explainParams()\")\nprintln(als.explainParams())\n\nprintln(\"\\n\\n\u003e\u003e\u003e\u003e als.extractParamMap()\")\nals.extractParamMap()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistFinal3.printSchema()\n\nval alsModel \u003d als.fit(userArtistFinal3)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userArtistFinal3\n    .groupBy(\"userid\")\n    .agg(count(\"artistid\").as(\"count_artist\"), sum(\"playcount\").as(\"sum_playcount\"))\n    .where(\"count_artist \u003e\u003d 20\")\n    .orderBy($\"count_artist\".asc, $\"sum_playcount\".desc)\n    .show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userDS \u003d Seq(1001440, 2010008, 987654321)\n    .toDF(\"userID\")\n    .as[Int]  // Dataset으로 형변환\n\nuserDS.printSchema\nuserDS.show(false)\n\n// 추천 5개\nval recommendedForSomeUsersDF \u003d alsModel.recommendForUserSubset(userDS, 5)\nrecommendedForSomeUsersDF.printSchema\nrecommendedForSomeUsersDF.show(false)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userDS \u003d Seq(1001440, 2010008, 987654321)\n    .toDF(\"userID\")\n    .as[Int]\n\nuserDS.printSchema\nuserDS.show(false)\n\n//추천 5개\nval recommendedForSomeUsersDF \u003d alsModel.recommendForUserSubset(userDS, 5)\nrecommendedForSomeUsersDF.printSchema\nrecommendedForSomeUsersDF.show(false)\n\nval recommendedForSomeUsersDF2 \u003d recommendedForSomeUsersDF\n    .withColumn(\"recommend\", explode($\"recommendations\"))\n    .withColumn(\"artistid\", $\"recommend.artistid\")\n    .withColumn(\"rating\", $\"recommend.rating\")\n\nrecommendedForSomeUsersDF2.printSchema()\nrecommendedForSomeUsersDF2.show(false)\nprintln(recommendedForSomeUsersDF2.count())\n\nval recommendedForSomeUsersDF3 \u003d recommendedForSomeUsersDF2\n    .drop(\"recommendations\", \"recommend\")\n\nrecommendedForSomeUsersDF3.printSchema()\nrecommendedForSomeUsersDF3.show(false)\nprintln(recommendedForSomeUsersDF3.count())\n\nval recommendedForSomeUsersDF4 \u003d recommendedForSomeUsersDF3.as(\"reco\")\n    .join(artistFinal.as(\"art\"), $\"reco.artistid\" \u003d\u003d\u003d $\"art.artistid\")\n    .orderBy($\"userid\".asc, $\"rating\".desc)\n\nrecommendedForSomeUsersDF4.show(false)\nz.show(recommendedForSomeUsersDF4)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val historyForSomeUsersDF \u003d userArtistFinal3\n    .where(\"userid in (1001440, 2010008)\").as(\"history\")\n    .join(artistFinal.as(\"art\"), $\"history.artistid\" \u003d\u003d\u003d $\"art.artistid\")\n    .orderBy($\"userid\".asc, $\"playcount\".desc)\n\nhistoryForSomeUsersDF.show(40, false)\nz.show(historyForSomeUsersDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val predictionsDF \u003d alsModel.transform(userArtistFinal3)\npredictionsDF.printSchema\n\npredictionsDF\n    .orderBy($\"prediction\".desc)\n    .show(false)\n\npredictionsDF\n    .orderBy($\"prediction\".asc)\n    .show(false)\n    "
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.evaluation.RegressionEvaluator\n\nval regEval \u003d new RegressionEvaluator()\n    .setLabelCol(\"playcount\")\n    .setPredictionCol(\"prediction\")\n    .setMetricName(\"rmse\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val rmse \u003d regEval.evaluate(predictionsDF)\n\nprintln(rmse)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.{Pipeline, PipelineModel}\n\nval pipeline \u003d new Pipeline()\n    .setStages(Array(als))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.tuning.ParamGridBuilder\n\nval paramMaps \u003d new ParamGridBuilder()\n    .addGrid(als.alpha, Array(40.0, 1.0))\n    .addGrid(als.rank, Array(2, 3))\n    .addGrid(als.regParam, Array(1.0, 0.01))\n    .build()\n\nprintln(paramMaps.mkString(\", \"))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.tuning.CrossValidator\n\nval cv \u003d new CrossValidator()\n    .setEstimator(pipeline)  \n    .setEstimatorParamMaps(paramMaps)  \n    .setEvaluator(regEval)  \n    .setNumFolds(2) \n"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val Array(trainDS, testDS) \u003d userArtistFinal3.randomSplit(Array(0.7, 0.3), 11L)\n\nprintln(userArtistFinal3.count)\n\ntrainDS.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY)\nprintln(trainDS.count)\n\ntestDS.persist(org.apache.spark.storage.StorageLevel.MEMORY_ONLY)\nprintln(testDS.count)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.tuning.CrossValidatorModel\n\nval cvModel \u003d cv.fit(trainDS)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(\"\\n\u003e\u003e\u003e\u003e Best Model : \\n\" + cvModel.bestModel)\nprintln(\"\\n\u003e\u003e\u003e\u003e Avg Metrics : \\n\" + cvModel.avgMetrics.mkString(\"\\n\"))\nprintln(\"\\n\u003e\u003e\u003e\u003e Estimator ParamMaps : \\n\" + cvModel.getEstimatorParamMaps.mkString(\"\\n\"))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val zippedParamAndMetrics \u003d cvModel.getEstimatorParamMaps\n    .zip(cvModel.avgMetrics)\n    .sortBy(_._2)\n\nprintln(\"\\n\u003e\u003e\u003e\u003e Zipped Param And Metrics : \\n\" + zippedParamAndMetrics.mkString(\"\\n\"))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val predictionsDF2 \u003d cvModel.transform(testDS)\npredictionsDF2.show()\n\nval rmse2 \u003d regEval.evaluate(predictionsDF2)\nprintln(rmse2)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "cvModel\n    .write\n    .overwrite\n    .save(\"hdfs://yms060-spark:9000/sungjin/model/audio/profiledata_06-May-2005/als_crossvalidator\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.recommendation._\n\nprintln(\"\\n\u003e\u003e\u003e\u003e CrossValidatorModel : \\n\" + cvModel)\nprintln(\"\\n\u003e\u003e\u003e\u003e CrossValidatorModel.bestModel : \\n\" + cvModel.bestModel)\n\nval pipelineBestModel \u003d cvModel.bestModel.asInstanceOf[PipelineModel]\n\nprintln(\"\\n\u003e\u003e\u003e\u003e PipelineModel.stages(0) : \\n\" + pipelineBestModel.stages(0))\n\nval alsBestModel \u003d pipelineBestModel.stages(0).asInstanceOf[ALSModel]\n\nalsBestModel\n    .write\n    .overwrite\n    .save(\"hdfs://yms060-spark:9000/sungjin/model/audio/profiledata_06-May-2005/als\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val loadedBestALSModel \u003d ALSModel.load(\"hdfs://yms060-spark:9000/sungjin/model/audio/profiledata_06-May-2005/als\")\n\nprintln(\"\\n\u003e\u003e\u003e\u003e model.extractParamMap : \\n\" + loadedBestALSModel.extractParamMap)\nprintln(\"\\n\u003e\u003e\u003e\u003e model.explainParams : \\n\" + loadedBestALSModel.explainParams)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userDS2 \u003d Seq(1001440, 2010008, 987654321)\n    .toDF(\"userID\")\n    .as[Int]\n\nuserDS2.printSchema\nuserDS2.show(false)\n\nval recommendedForSomeUsersDF2 \u003d loadedBestALSModel.recommendForUserSubset(userDS2, 5)\nrecommendedForSomeUsersDF2.printSchema\nrecommendedForSomeUsersDF2.show(false)\nz.show(recommendedForSomeUsersDF2)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userDS2 \u003d Seq(1001440, 2010008, 987654321)\n    .toDF(\"userID\")\n    .as[Int] \n\nuserDS2.printSchema\nuserDS2.show(false)\n\nval recommendedForSomeUsersDF2 \u003d loadedBestALSModel.recommendForUserSubset(userDS2, 5)\nrecommendedForSomeUsersDF2.printSchema\nrecommendedForSomeUsersDF2.show(false)\n\nval recommendedForSomeUsersDF22 \u003d recommendedForSomeUsersDF2\n    .withColumn(\"recommend\", explode($\"recommendations\"))\n    .withColumn(\"artistid\", $\"recommend.artistid\")\n    .withColumn(\"rating\", $\"recommend.rating\")\n\nrecommendedForSomeUsersDF22.printSchema()\nrecommendedForSomeUsersDF22.show(false)\nprintln(recommendedForSomeUsersDF22.count())\n\nval recommendedForSomeUsersDF33 \u003d recommendedForSomeUsersDF22\n    .drop(\"recommendations\", \"recommend\")\n\nrecommendedForSomeUsersDF33.printSchema()\nrecommendedForSomeUsersDF33.show(false)\nprintln(recommendedForSomeUsersDF33.count())\n\nval recommendedForSomeUsersDF44 \u003d recommendedForSomeUsersDF33.as(\"reco\")\n    .join(artistFinal.as(\"art\"), $\"reco.artistid\" \u003d\u003d\u003d $\"art.artistid\")\n    .orderBy($\"userid\".asc, $\"rating\".desc)\n\nrecommendedForSomeUsersDF44.show(false)\nz.show(recommendedForSomeUsersDF44)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val recommendedForAllUsersDF \u003d loadedBestALSModel.recommendForAllUsers(5)\n\nrecommendedForAllUsersDF.printSchema\nrecommendedForAllUsersDF.show(false)\nprintln(recommendedForAllUsersDF.count)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val recommendedForAllUsersDF2 \u003d recommendedForAllUsersDF\n    .withColumn(\"recommendation\", explode($\"recommendations\"))\n    .withColumn(\"artistid\", $\"recommendation.artistid\")\n    \nrecommendedForAllUsersDF2.printSchema\nrecommendedForAllUsersDF2.show(false)\nprintln(recommendedForAllUsersDF2.count)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val recommendedForAllUsersDF3 \u003d recommendedForAllUsersDF2\n    .groupBy(\"userid\")\n    .agg(collect_list(\"artistid\").as(\"artistid_list\"))\n    .withColumn(\"recommended_artistids\", array_join(col(\"artistid_list\"), \" \"))\n    \nrecommendedForAllUsersDF3.printSchema\nrecommendedForAllUsersDF3.show(false)\nprintln(recommendedForAllUsersDF3.count)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val recommendedForAllUsersDF4 \u003d recommendedForAllUsersDF3.select($\"userid\", $\"recommended_artistids\")\nrecommendedForAllUsersDF4.printSchema\nrecommendedForAllUsersDF4.show(false)\nprintln(recommendedForAllUsersDF4.count)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "recommendedForAllUsersDF4\n    .write\n    .format(\"org.apache.spark.sql.redis\")\n    .option(\"table\", \"user_artists\")\n    .option(\"key.column\", \"userid\")\n    .mode(\"append\")\n    .save()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val recommendedForAllUsersDF5 \u003d spark\r\n    .read\r\n    .format(\"org.apache.spark.sql.redis\")\r\n    .option(\"table\", \"user_artists\")\r\n    .option(\"key.column\", \"userid\")\r\n    .load()\r\n\r\nrecommendedForAllUsersDF5.printSchema\r\nrecommendedForAllUsersDF5.show(false)\r\nprintln(recommendedForAllUsersDF5.count)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val recommendedForAllUsersDF4 \u003d spark\r\n    .read\r\n    .format(\"org.apache.spark.sql.redis\")\r\n    .option(\"keys.pattern\", \"user_artists:2127894\")\r\n    .option(\"key.column\", \"userid\")\r\n    .option(\"infer.schema\", true)\r\n    .load()\r\n\r\nrecommendedForAllUsersDF4.printSchema\r\nrecommendedForAllUsersDF4.show(false)\r\n"
    }
  ]
}